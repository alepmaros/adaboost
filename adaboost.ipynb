{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TP2 - Algoritmo de Boosting - Aprendizado de Máquina\n",
    "## Nome: Alexandre Maros\n",
    "\n",
    "PPGCC - UFMG - 2018/1\n",
    "\n",
    "Este é o notebook referente ao segundo trabalho prático da disciplina de Aprendizado de Máquina da UFMG\n",
    "\n",
    "O objetivo é implementar o algoritmo de Boosting, completamente do 0, sem a ajuda de bibliotecas externas e com Decision Stumps.\n",
    "\n",
    "O dataset que deve ser utilizado é o do Tic-Tac-Toe e está disponivel em https://archive.ics.uci.edu/ml/datasets/Tic-Tac-Toe+Endgame, o objetivo é identificar se o 'x' vai ganhar (positivo) ou não (negativo) dado uma instância do tabuleiro qualquer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, time, math, random, itertools\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "pd.options.display.max_rows = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = pd.read_csv('data/tic-tac-toe.data', header=None)\n",
    "data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Armazenar o label correto dos numeros\n",
    "data = data2.rename(columns = {9:'label'})\n",
    "# Trocar positivo por +1 e negativo por -1\n",
    "data['label'] = data['label'].replace({'positive': 1, 'negative': -1})\n",
    "\n",
    "# Separar label das features\n",
    "y = data.label\n",
    "X = data.drop(\"label\", axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definição de Funções de Utilidade\n",
    "\n",
    "Função __plot_loss_curve__: Simples função para _plottar_ as curvas de treino e teste para o ensemble e a curva de erro para o modelo fraco, variando a quantidade de modelos fracos utilizados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss_curve(xs, ensemble_training_error, ensemble_test_error, model_err_train, title='Error Curve'):\n",
    "    timestamp = str(time.time()).split('.')[0]\n",
    "    fig = plt.figure(figsize=(11, 6), dpi= 80)\n",
    "    plt.style.use('ggplot')\n",
    "    plt.title(title)\n",
    "    plt.ylabel('Error Rate')\n",
    "    plt.xlabel('Number of Weak Learners')\n",
    "    plt.plot(xs, ensemble_training_error, 'b-', label=\"Ensemble Training Error\")\n",
    "    plt.plot(xs, ensemble_test_error, 'r-', label=\"Ensemble Test Error\")\n",
    "    plt.plot(xs, model_err_train, 'm-', label=\"Weak Model Training Error\")\n",
    "    plt.legend(loc=\"best\")\n",
    "    plt.savefig('loss_curve_' + timestamp + '.pdf', format='pdf', bbox_inches='tight' )\n",
    "    return plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Função __k_fold__: Função para fazer a técnica de validação cruzada K-Fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_fold(dataset, folds=5):\n",
    "    indexes_split = []\n",
    "    indexes = list(dataset.index)\n",
    "    fold_size = int(dataset.shape[0] / folds)\n",
    "    for i in range(folds):\n",
    "        fold = []\n",
    "        while len(fold) < fold_size:\n",
    "            index = random.randrange(len(indexes))\n",
    "            fold.append(indexes.pop(index))\n",
    "        indexes_split.append(fold)\n",
    "    return indexes_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementação do Decision Stump\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionStump:\n",
    "    def __init__(self):\n",
    "        # Possiveis categorias que o dado vai ter para poder realizar as perguntas (Tem x na posição 0?)\n",
    "        # No caso do tick-tack-toe vai ser x, o e b\n",
    "        self.unique_categories = []\n",
    "        # Dimensionalidade do dado, para saber quantas possíveis posições pode ter\n",
    "        self.data_dimension = 0\n",
    "        \n",
    "        self.model = {\n",
    "            'question_column' : None,\n",
    "            'question_cat'    : None,\n",
    "            'value'           : None,\n",
    "            'train_weighted_error' : None,\n",
    "            'train_accuracy'       : None\n",
    "        }\n",
    "        \n",
    "    def fit(self, X, y, weights):\n",
    "        \"\"\"Seleciona o modelo com base em X, y e os pesos de cada entrada\"\"\"\n",
    "        \n",
    "        # Guarda todos os valores possiveis para todas as colunas e a dimensao dos dados\n",
    "        # No caso do Tick-Tack-Toe, sera x,o,b para todas\n",
    "        for column in X:\n",
    "            self.unique_categories.append(X[column].unique())\n",
    "        self.data_dimension = len(list(X))\n",
    "        \n",
    "        best_model_error = 1\n",
    "        for i in range(0, self.data_dimension):\n",
    "            for cat in self.unique_categories[0]:\n",
    "                for value in (-1, 1):\n",
    "                    error = self._compute_training_error(X, y, i, cat, value, weights=weights)\n",
    "                    if (error[0] < best_model_error):\n",
    "                        best_model_error  = error[0]\n",
    "                        self.model['question_column'] = i\n",
    "                        self.model['question_cat']    = cat\n",
    "                        self.model['value']           = value\n",
    "                        self.model['train_weighted_error'] = error[0]\n",
    "                        self.model['train_acccuracy']      = error[1]\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"Prevê os valores das entradas em X\"\"\"\n",
    "        if (self.model['question_column'] == None):\n",
    "            print('Model was not fitted')\n",
    "            return\n",
    "        \n",
    "        predictions = []\n",
    "        for row in X:\n",
    "            if( row[self.model['question_column']] == self.model['question_cat'] ):\n",
    "                predictions.append(self.model['value'])\n",
    "            else:\n",
    "                predictions.append(-self.model['value'])\n",
    "        return predictions\n",
    "    \n",
    "    def _compute_training_error(self, X, y, question_column, question_cat, value, weights=None):\n",
    "        nb_samples  = X.count()[0]\n",
    "        right_count = 0\n",
    "        error = 0\n",
    "        for i, row in X.iterrows():\n",
    "            if( (row[question_column] == question_cat and y[i] == value) or \n",
    "                  (row[question_column] != question_cat and y[i] != value) ):\n",
    "                right_count += 1\n",
    "            else:\n",
    "                error += weights[i]\n",
    "        \n",
    "        accuracy = right_count / float(nb_samples)\n",
    "        \n",
    "        # Error is weighted error, for actual error do 1-accuracy\n",
    "        return (error, accuracy)\n",
    "    \n",
    "    def get_empirical_weighted_error(self):\n",
    "        return self.model['train_weighted_error']\n",
    "    \n",
    "    def get_empirical_accuracy(self):\n",
    "        return self.model['train_acccuracy']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementação do algoritmo de Boosting\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdaBoost:\n",
    "    def __init__(self, nb_estimators = 30):\n",
    "        self.nb_estimators = nb_estimators\n",
    "        self.models  = []\n",
    "        self.weights = []\n",
    "        self.alphas  = []\n",
    "        \n",
    "        self.models_error_rate = []\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        \n",
    "        # Calculate initial weights\n",
    "        weights = pd.Series(index=y.index.copy())\n",
    "        weights[:] = 1.0 / y.shape[0]\n",
    "        self.weights.append( weights )\n",
    "        \n",
    "        for i in range(0, self.nb_estimators):\n",
    "            # Calculate new models\n",
    "            dt = DecisionStump()\n",
    "            dt.fit(X, y, self.weights[i])\n",
    "            self.models.append(dt)\n",
    "            self.models_error_rate.append(dt.get_empirical_weighted_error())\n",
    "            \n",
    "            # Calculate new alpha\n",
    "            error = dt.get_empirical_weighted_error()\n",
    "            alpha = 0.5 * math.log( (1 - error) / error )\n",
    "            self.alphas.append(alpha)\n",
    "            \n",
    "            # Calculate new weights\n",
    "            new_weights = pd.Series(index=y.index.copy())\n",
    "            right_count = 0\n",
    "            for index, _ in new_weights.iteritems():\n",
    "                prediction = dt.predict(np.array([ X.loc[index].values ]))[0]\n",
    "                true_y     = y[index]\n",
    "                new_weights[index] = self.weights[i][index] * math.exp( -alpha * prediction * true_y )\n",
    "                    \n",
    "            new_weights = new_weights.apply(lambda x: float(x) / new_weights.sum())\n",
    "            self.weights.append( new_weights )\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def _sign(self, value):\n",
    "        if (value >= 0):\n",
    "            return 1\n",
    "        return -1\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"Prevê os valores das entradas em X\"\"\"\n",
    "        if ( len(self.models) == 0 ):\n",
    "            print('Model was not fitted')\n",
    "            return\n",
    "        \n",
    "        predictions = []\n",
    "        for row in X:\n",
    "            sum_predictions = np.sum([ dt.predict([row])[0] * self.alphas[i] for i,dt in enumerate(self.models)])\n",
    "            predictions.append( self._sign(sum_predictions))\n",
    "        return predictions\n",
    "    \n",
    "    def compute_ensemble_error_rate(self, X, y):\n",
    "        if ( len(self.models) == 0 ):\n",
    "            print('Model was not fitted')\n",
    "            return\n",
    "        \n",
    "        ensemble_error_rate = []\n",
    "        for j in range(1, len(self.models)+1):\n",
    "            right_count = 0\n",
    "            for z, row in enumerate(X):\n",
    "                sum_predictions = np.sum(\n",
    "                    [ dt.predict([row])[0] * self.alphas[i] for i,dt in enumerate(self.models[0:j])])\n",
    "                if (self._sign(sum_predictions) == y[z]):\n",
    "                    right_count += 1\n",
    "            accuracy = right_count / float(y.shape[0])\n",
    "            ensemble_error_rate.append( 1-accuracy )\n",
    "                \n",
    "        return ensemble_error_rate\n",
    "    \n",
    "    def compute_test_error_rate(self, X, y):\n",
    "        if ( len(self.models) == 0 ):\n",
    "            print('Model was not fitted')\n",
    "            return\n",
    "        \n",
    "        right_count = 0\n",
    "        for z, row in enumerate(X):\n",
    "            prediction = self.predict([row])[0]\n",
    "            if (prediction == y[z]):\n",
    "                right_count += 1\n",
    "        accuracy = right_count / float( len(y) )\n",
    "        return (1 - accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experimentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = 5\n",
    "nb_estimators = 300\n",
    "lst_ensemble_err_train = []\n",
    "lst_ensemble_err_test  = []\n",
    "lst_model_err_train    = []\n",
    "\n",
    "indexes = k_fold(X, folds=folds)\n",
    "for i, test_indexes in enumerate(indexes):\n",
    "    print('Test {}/{}:'.format(i+1,folds))\n",
    "    \n",
    "    train_indexes = [ x for j,x in enumerate(indexes) if j != i ]\n",
    "    train_indexes = list(itertools.chain.from_iterable(train_indexes))\n",
    "    \n",
    "    X_train = X.iloc[train_indexes]\n",
    "    y_train = y.iloc[train_indexes]\n",
    "    X_test  = X.iloc[test_indexes]\n",
    "    y_test  = y.iloc[test_indexes]\n",
    "\n",
    "    adb = AdaBoost(nb_estimators=nb_estimators)\n",
    "    start = time.time()\n",
    "    adb.fit(X_train, y_train)\n",
    "    end   = time.time()\n",
    "    print('\\tFitting took {} seconds'.format(end-start))\n",
    "    ensemble_err_train = adb.compute_ensemble_error_rate(X_train.values, y_train.values)\n",
    "    enemble_err_test   = adb.compute_ensemble_error_rate(X_test.values, y_test.values)\n",
    "    model_err_train    = adb.models_error_rate\n",
    "    \n",
    "    lst_ensemble_err_train.append(ensemble_err_train)\n",
    "    lst_ensemble_err_test.append(enemble_err_test)\n",
    "    lst_model_err_train.append(model_err_train)\n",
    "\n",
    "plot_loss_curve([x for x in range(1,nb_estimators+1)],\n",
    "                np.mean(lst_ensemble_err_train, axis=0),\n",
    "                np.mean(lst_ensemble_err_test, axis=0),\n",
    "                np.mean(lst_model_err_train, axis=0),\n",
    "                title='Error Curves for AdaBoost with 5-Fold CV')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_err = 2\n",
    "nb_wk_learners = 0\n",
    "for i, err in enumerate(np.mean(lst_ensemble_err_test, axis=0)):\n",
    "    if (err < min_err):\n",
    "        min_err = err\n",
    "        nb_wk_learners = i+1\n",
    "print('Best model found used {0:} estimators and model got accuracy of {1:.3f}%'.format(nb_wk_learners, (1-min_err)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = 5\n",
    "\n",
    "adb50_test_error   = []\n",
    "adb150_test_error  = []\n",
    "adb250_test_error  = []\n",
    "adb250_alphas      = []\n",
    "\n",
    "indexes = k_fold(X, folds=folds)\n",
    "for i, test_indexes in enumerate(indexes):\n",
    "    print('Test {}/{}'.format(i+1,folds))\n",
    "    \n",
    "    train_indexes = [ x for j,x in enumerate(indexes) if j != i ]\n",
    "    train_indexes = list(itertools.chain.from_iterable(train_indexes))\n",
    "    \n",
    "    X_train = X.iloc[train_indexes]\n",
    "    y_train = y.iloc[train_indexes]\n",
    "    X_test  = X.iloc[test_indexes]\n",
    "    y_test  = y.iloc[test_indexes]\n",
    "    \n",
    "    adb50  = AdaBoost(nb_estimators=50)\n",
    "    adb150 = AdaBoost(nb_estimators=150)\n",
    "    adb250 = AdaBoost(nb_estimators=250)\n",
    "    \n",
    "    adb50.fit(X_train, y_train)\n",
    "    adb150.fit(X_train, y_train)\n",
    "    adb250.fit(X_train, y_train)\n",
    "    \n",
    "    adb250_alphas.append( adb250.alphas )\n",
    "    \n",
    "    adb50_test_error.append( adb50.compute_test_error_rate(X_test.values, y_test.values) )\n",
    "    adb150_test_error.append( adb150.compute_test_error_rate(X_test.values, y_test.values) )\n",
    "    adb250_test_error.append( adb250.compute_test_error_rate(X_test.values, y_test.values) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp = str(time.time()).split('.')[0]\n",
    "fig = plt.figure(figsize=(11, 6), dpi= 80)\n",
    "plt.style.use('ggplot')\n",
    "plt.title('Error rate with different number of estimators and 5-Fold CV')\n",
    "plt.ylabel('Error Rate')\n",
    "plt.boxplot( [adb50_test_error, adb150_test_error, adb250_test_error] )\n",
    "plt.xticks([1,2,3], ['50 Estimators', '150 Estimators', '250 Estimators'] )\n",
    "plt.savefig('boxplot_' + timestamp + '.pdf', format='pdf', bbox_inches='tight' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp = str(time.time()).split('.')[0]\n",
    "fig = plt.figure(figsize=(11, 6), dpi= 80)\n",
    "plt.style.use('ggplot')\n",
    "plt.title('Variation of model importance (alphas) using 250 estimators')\n",
    "plt.ylabel('Model importance (Alpha Value)')\n",
    "plt.xlabel('Estimator number')\n",
    "plt.plot( [x for x in range(1,250+1)], np.mean(adb250_alphas, axis=0), 'b-', label='Alpha')\n",
    "plt.legend(loc=\"best\")\n",
    "plt.savefig('alphas_' + timestamp + '.pdf', format='pdf', bbox_inches='tight' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusões"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
